{
  "input": {
    "workflow": {
      "6": {
        "inputs": {
          "text": "magazine cover photo of a black supermodel, full body shot, low angle view from her feet, wide-angle lens, watching the sunset, hyperrealistic, vogue style",
          "clip": ["57", 0]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Positive Prompt)"
        }
      },
      "8": {
        "inputs": {
          "samples": ["55", 0],
          "vae": ["10", 0]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "9": {
        "inputs": {
          "filename_prefix": "RunPod_Test",
          "images": ["8", 0]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "Save Image"
        }
      },
      "10": {
        "inputs": {
          "vae_name": "ae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "Load VAE"
        }
      },
      "26": {
        "inputs": {
          "guidance": 3.5,
          "conditioning": ["6", 0]
        },
        "class_type": "FluxGuidance",
        "_meta": {
          "title": "FluxGuidance"
        }
      },
      "27": {
        "inputs": {
          "width": 832,
          "height": 1280,
          "batch_size": 1
        },
        "class_type": "EmptySD3LatentImage",
        "_meta": {
          "title": "EmptySD3LatentImage"
        }
      },
      "30": {
        "inputs": {
          "max_shift": 1.25,
          "base_shift": 0.5,
          "width": 832,
          "height": 1280,
          "model": ["62", 0]
        },
        "class_type": "ModelSamplingFlux",
        "_meta": {
          "title": "ModelSamplingFlux"
        }
      },
      "45": {
        "inputs": {
          "model_path": "svdq-int4_r32-flux.1-dev.safetensors",
          "cache_threshold": 0,
          "attention": "nunchaku-fp16",
          "cpu_offload": "auto",
          "device_id": 0,
          "data_type": "bfloat16",
          "i2f_mode": "enabled"
        },
        "class_type": "NunchakuFluxDiTLoader",
        "_meta": {
          "title": "Nunchaku FLUX DiT Loader"
        }
      },
      "46": {
        "inputs": {
          "lora_name": "FLUX.1-Turbo-Alpha.safetensors",
          "lora_strength": 1,
          "model": ["45", 0]
        },
        "class_type": "NunchakuFluxLoraLoader",
        "_meta": {
          "title": "Nunchaku FLUX LoRA Loader"
        }
      },
      "55": {
        "inputs": {
          "seed": 326646439271006,
          "steps": 8,
          "cfg": 1,
          "sampler_name": "euler",
          "scheduler": "simple",
          "denoise": 1,
          "model": ["30", 0],
          "positive": ["26", 0],
          "negative": ["56", 0],
          "latent_image": ["27", 0]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "56": {
        "inputs": {
          "conditioning": ["6", 0]
        },
        "class_type": "ConditioningZeroOut",
        "_meta": {
          "title": "ConditioningZeroOut"
        }
      },
      "57": {
        "inputs": {
          "model_type": "flux.1",
          "text_encoder1": "awq-int4-flux.1-t5xxl.safetensors",
          "text_encoder2": "clip_l.safetensors",
          "t5_min_length": 512
        },
        "class_type": "NunchakuTextEncoderLoaderV2",
        "_meta": {
          "title": "Nunchaku Text Encoder Loader V2"
        }
      },
      "62": {
        "inputs": {
          "lora_name": "flux-super-realism.safetensors",
          "lora_strength": 1,
          "model": ["46", 0]
        },
        "class_type": "NunchakuFluxLoraLoader",
        "_meta": {
          "title": "Nunchaku FLUX LoRA Loader"
        }
      }
    }
  }
}
